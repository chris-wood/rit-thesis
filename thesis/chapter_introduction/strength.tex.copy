\section{Effecient Computations of Cryptographic Properties of S-Boxes} \label{sec:strength}
The strength of S-boxes can be measured using in the context of Galois fields and Boolean functions. In this section, we focus on several important measurements of the cryptographic strength of cryptographic S-boxes in the context of Galois fields, including differential uniformity and algebraic complexity. We then present measurements of strength that can be measured in the context of one-dimensional Boolean functions, including nonlinearity (and nonlinear profile), resiliency, the strict avalanche criterion, and algebraic immunity. We then extend these measurements to $(n,m)$ Boolean functions.

\subsection{Linear Approximation and Difference Distribution}
With the advent of linear and differential cryptanalysis on SPN block ciphers, the contents of the 
linear approximation and difference distribution tables, which are highly dependent on the S-box 
used in such block ciphers, are critical in determining a particular construction's susceptibility 
to these attacks. Based on the definitions given in the preceding section, we can compute the 
$N_L(a,b)$ matrix using the procedure outlined in Algorithm \ref{alg:claAlg}. The exhaustive
nature of this algorithm yields a time complexity of $\mathcal{O}(2^{4n})$, which means that for 
S-boxes where $n = 16$, computing this table cannot be done on a normal computer. For this purpose,
we turn to the Open Science Grid (OSG) \cite{} to compute this $2^{16} \times 2^{16}$ element
matrix. An ideal S-box will have probabilities around 0.5 for all input and output combinations, meaning
that linear combinations do not occur with non-random frequency, which is needed to carry out a successful
linear cryptanalysis attack.

\begin{algorithm}[t!] %[htb]
\caption{CLA($S_S, n$)} \label{alg:claAlg}
\begin{algorithmic}[1]
\State $N_L \gets zeros(1...2^n - 1,1...2^n - 1)$
	\For {$a = 0 \to 2^n - 1$}
		\For {$b = 0 \to 2^n - 1$}
			\For {$x = 0 \to 2^n - 1$}
				\For {$y = 0 \to 2^n - 1$}
					\If {$S_S(x) == y$ AND $SumXOR(a,b,x,y) == 0$}
						\State $N_L(a,b) \gets N_L(a,b) + 1$
					\EndIf		
				\EndFor
			\EndFor
		\EndFor
	\EndFor
\\
	\Function{SumXOR}{$a,b,x,y$}
		\State $x' = x \land a$ \Comment {$a \cdot x$}
		\State $y' = y \land b$ \Comment {$b \cdot y$}
		\State \Return WEIGHT$(x' \oplus y')$ 
	\EndFunction
\end{algorithmic}
\end{algorithm}

As discussed in the previous chapter, differential cryptanalysis relies on the difference
distribution table, $N_D(\Delta X, \Delta Y)$. Since this table is generated from an exhaustive
check of all input and output differences, we compute it very similar to $N_L(a,b)$ using
Algorithm \ref{alg:ddtable}. Again, we have a time complexity of $\mathcal{O}(2^{4n})$, and
use the same computation technique as we followed for $N_L(a,b)$ for large $n$.

\begin{algorithm}[t!]
\caption{$N_D(\Delta X, \Delta Y), S$}) \label{alg:ddtable}
\begin{algorithmic}[1]
\State $N_D \gets zeros(1...2^n - 1,1...2^n - 1)$
\For {$x_1 = 0 \to 2^n - 1$}
	\For {$x_2 = 0 \to 2^n - 1$}
		\State $\Delta X = x_1 \oplus x_2$
		\State $\Delta Y = S[x_1] \oplus S[x_2]$
		\State $N_D[\Delta X, \Delta Y] \gets N_D[\Delta X, \Delta Y] + 1$
	\EndFor
\EndFor
\State \Return $N_D$
\end{algorithmic}
\end{algorithm}

\subsection{Differential Uniformity}
First introduced in 1994 by Nyberg \cite{Nyberg94-1}, we say that an 
S-box $F : GF(2^n) \to GF(2^m)$ is $\delta$-differentially uniform if for all $\alpha \in GF(2^n)$
and $\beta \in GF(2^m)$ we have
\begin{align*}
|\{x \in GF(2^n) | D_{\alpha}F(x) = \beta\}| \leq \delta,
\end{align*}
where $D_{\alpha}F(x) = F(x + \alpha) + F(x)$, $\alpha \in GF(2^n)$, and $\beta \in GF(2^m)$.
Equivalently, we say that such an S-box $F : GF(2^n) \to GF(2^m)$ is $\delta$-differentially
uniform if $F(x + \alpha) + F(x) = \beta$ has at most $\delta$ solutions in $GF(2^n)$.
Differential cryptanalysis exploits the lack of uniformity in the nonlinear S-box
step of SPN block ciphers. More specifically, differential cryptanalysis exploits
an uneven distribution in the cardinality of the sets $\{D_{\alpha}F(x) : x,\alpha \in GF(2^n)\}$.
Intuitively, an uneven distribution implies that there exists a single element
$\beta \in GF(2^m)$ that is mapped to with higher frequency given two different
input elements $x$ and $\alpha$. In an ideal SPN block cipher, the probability
that a given input difference $\Delta X$ will yield a specific output difference
$\Delta Y$ should be exactly $2^{-n}$, where $n = m$ is the size of the input
and output elements. If an S-box is not differentially 1-uniform, then there will exist
a value $\beta \in GF(2^m)$ such that for any two randomly selected input elements
$x$ and $\alpha$, $\beta$ will be the output. From an attacker's perspective, this
means that there will exist an output difference $\Delta Y$ that occurs with much
higher probabilty for a select of input differences $\Delta X$.

Clearly, cryptographically strong S-boxes have low values for
$\delta$, as this means the output of $F$ is relatively uniform and the frequency of a 
single output value cannot be easily exploited for an attack. 
Differential uniformity was first studied in the context of the Data Encryption
Standard, and it was proven in \cite{Nyberg94-1} that if the round functions of
Feistel-based ciphers similar to DES are $\delta$-differentially uniform, then 
the average probability to obtain a non-zero output for input $x + \alpha$, for
all $x, \alpha \in GF(2^n)$, after $s = 4$ rounds is bounded by $2(\frac{\delta}{2^n})^2$.

Functions achieving this bound with $\delta = 1$ are referred to as \emph{perfectly 
nonlinear}. Similarly, functions achieving this bound with $\delta = 2$ are referred
to as \emph{almost perfectly nonlinear} functions \cite{Nyberg91-1}. 

S-boxes of the form $F(x) : x^{-1}$ were shown to be differentially $4$-uniform 
with a $\mathcal{N}_l$ lower bound of $2^{n-1} - 2^{\frac{n}{2}}$ in \cite{Nyberg94-1}.
Similarly, S-boxes of the form $F(x) = x^{2^{k} + 1}$ are differentially $2$-unfiform
with a $\mathcal{N}_l$ equal to precisely $2^{n-1} - 2^{\frac{n-1}{2}}$. With the selection
of Rijndael as the AES in 2001 \cite{Daemen02-1}, S-boxes of the form $F(x) : x^{-1}$
became the primary subject of study in the literature. 
Constructions of perfect and almost perfect nonlinear functions have been the subject
of much research activity the past decade. In Section \ref{sec:bfConstruct} we revisit
this topic in much greater detail. 

The Python code to compute the differential uniformity of an $(n,n)$ Boolean function 
(i.e. an S-box $F : GF(2^n) \to GF(2^n)$) is shown in Listing \ref{lst:differentialUniformity}.
Given the exhaustive nature of this algorithm, its time complexity is on the order
of $\mathcal{O}((2^n)^3) = \mathcal{O}(2^{3n})$. 

\begin{lstlisting}[
language=Python, 
basicstyle=\small\sffamily,
numbers=left,
frame=tb,
columns=fullflexible,
showstringspaces=false,
caption=Python function to compute the differential uniformity of an S-box $S$ defined as a map from input to output elements.]
def differentialUniformity(S):
	c = 0
	delta = 0
	n = len(S)
	for alpha in range(1, n): 
		for beta in range(n):
			c = 0
			for z in range(n):
				if ((S[(z ^ alpha)] ^ S[z]) == beta):
					c = c + 1
			if (c > delta): 
				delta = c
	return delta 
\end{lstlisting} \label{lst:differentialUniformity}

\subsection{Nonlinearity}
Since Boolean functions are natural representations for S-boxes, the measure of nonlinearity becomes
fundamental in the assessment of the cryptographic strength of S-boxes. For a Boolean function $f$,
the nonlinearity $\mathcal{N}_l$ is defined as the minimum distance between $f$ and all possible affine functions
on $n$ variables. Formally, we define the nonlinearity as follows \cite{cusik09-BooleanFunctions}:
\begin{align*}
\mathcal{N}_l(f) = \min_{\phi \in \Omega_n} d(f, \phi),
\end{align*}
where $d(f, g) = wt(f \oplus g)$ (i.e. the Hamming distance between two functions $f$ and $g$). 
The maximum value for $\mathcal{N}_l$ is $2^{n-1} - 2^{n/2 - 1}$.
It is also convenient to use the Walsh-Hadmard transform of a Boolean 
function $f$ as $W_f(u) = \sum_{x \in \mathbb{F}_2^n} (-1)^{f(x) \oplus (u \cdot x)}$,
where $w \in \mathbb{F}_2^n$ and $w \cdot x$ is the inner product of the 
two vectors $w, x \in \mathbb{F}_2$ \cite{cusik09-BooleanFunctions}, 
to define the nonlinearity of a function $f$ as 
\begin{align*}
2^{n-1} - \frac{1}{2}\max_{u \in \mathbb{F}_2^n}|W_f(u)|.
\end{align*}
If $n$ is odd then one-dimensional Boolean function $F$ is called maximally nonlinear if the Walsh spectra,
which is the set $\{W_f(u) : u \in \mathbb{F}_2^m \}$, of all nonzero linear combinations
of the component functions $f_i$, $0 \leq i < m$, takes on exactly three values from the 
set $\{0, \pm 2^{(n+1)/2}\}$ \cite{Nawaz09-1}. The same cannot be said for even values of $n$, which
are of interest in this thesis. It has, however, been conjectured that a maximum upper bound
on the nonlinearity for such functions is $2^{n-1} - 2^{n/2}$, and we call a function $F$
\emph{maximally nonlinear} if it achieves this bound \cite{Dobbertin99-1}. Maximally nonlinear
Boolean functions are also called \emph{bent functions}, and were first introduced by Rothaus  
in 1976 \cite{Rothaus76-1}. Nyberg studied the properties and constructions of 
``perfectly nonlinear'' (bent) functions using the discrete Fourier transform \cite{Nyberg91-1}.

\begin{figure}
\centering
\begin{tikzpicture}
[bend angle =60,inner sep=0pt, minimum size =10mm,very thick,
from/.style={<-},
towards/.style={->},
field/.style={},
sub/.style={draw, thin, color=red, ->, >=stealth},
add/.style={draw, thin, color=black,->, >=stealth},]
\node[field] (f18) at (0,8) {1};
\node[field] (f17) at (0,7) {0};
\node[field] (f16) at (0,6) {1};
\node[field] (f15) at (0,5) {0};
\node[field] (f14) at (0,4) {1};
\node[field] (f13) at (0,3) {1};
\node[field] (f12) at (0,2) {0};
\node[field] (f11) at (0,1) {0};

\node[field] (f28) at (4,8) {$1+1 = 2$};
\node[field] (f27) at (4,7) {$0+1=1$};
\node[field] (f26) at (4,6) {$1+0=1$};
\node[field] (f25) at (4,5) {$0+0=0$};
\node[field] (f24) at (4,4) {$-1+1=0$};
\node[field] (f23) at (4,3) {$-1+0=-1$};
\node[field] (f22) at (4,2) {$-0+1=1$};
\node[field] (f21) at (4,1) {$-0+0=0$};

\node[field] (f38) at (8,8) {$2+1=3$};
\node[field] (f37) at (8,7) {$1+0=1$};
\node[field] (f36) at (8,6) {$-1+2=1$};
\node[field] (f35) at (8,5) {$-0+1=1$};
\node[field] (f34) at (8,4) {$0+1=1$};
\node[field] (f33) at (8,3) {$-1+0=-1$};
\node[field] (f32) at (8,2) {$-1+0=-1$};
\node[field] (f31) at (8,1) {$-0+-1=-1$};

\node[field] (f48) at (12,8) {$3+1=4$};
\node[field] (f47) at (12,7) {$-1+3=2$};
\node[field] (f46) at (12,6) {$1+1=2$};
\node[field] (f45) at (12,5) {$-1+1=0$};
\node[field] (f44) at (12,4) {$1+-1=0$};
\node[field] (f43) at (12,3) {$-(-1) + 1 = 2$};
\node[field] (f42) at (12,2) {$-1 + -1 = -2$};
\node[field] (f41) at (12,1) {$-(-1) + -1 = 0$};

% PASS 1
\draw [add] (1,8) -- (2.5,8);
\draw [add] (1,7) -- (2.5,7);
\draw [add] (1,6) -- (2.5,6);
\draw [add] (1,5) -- (2.5,5);

\draw [add] (1,8) -- (2.5,4);
\draw [add] (1,7) -- (2.5,3);
\draw [add] (1,6) -- (2.5,2);
\draw [add] (1,5) -- (2.5,1);

\draw [add] (1,4) -- (2.5,8);
\draw [add] (1,3) -- (2.5,7);
\draw [add] (1,2) -- (2.5,6);
\draw [add] (1,1) -- (2.5,5);

\draw [sub] (1,4) -- (2.5,4);
\draw [sub] (1,3) -- (2.5,3);
\draw [sub] (1,2) -- (2.5,2);
\draw [sub] (1,1) -- (2.5,1);

% PASS 2
\draw [add] (5.25,8) -- (6.5,8);
\draw [add] (5.25,7) -- (6.5,7);
\draw [sub] (5.25,6) -- (6.5,6);
\draw [sub] (5.25,5) -- (6.5,5);

\draw [add] (5.25,8) -- (6.5,6);
\draw [add] (5.25,7) -- (6.5,5);
\draw [add] (5.25,6) -- (6.5,8);
\draw [add] (5.25,5) -- (6.5,7);

\draw [add] (5.25,4) -- (6.5,2);
\draw [add] (5.25,3) -- (6.5,1);
\draw [add] (5.25,2) -- (6.5,4);
\draw [add] (5.25,1) -- (6.5,3);

\draw [add] (5.25,4) -- (6.5,4);
\draw [add] (5.25,3) -- (6.5,3);
\draw [sub] (5.25,2) -- (6.5,2);
\draw [sub] (5.25,1) -- (6.5,1);

% PASS 3
\draw [add] (9.5,8) -- (10.25,8);
\draw [sub] (9.5,7) -- (10.25,7);
\draw [add] (9.5,6) -- (10.25,6);
\draw [sub] (9.5,5) -- (10.25,5);

\draw [add] (9.5,8) -- (10.25,7);
\draw [add] (9.5,7) -- (10.25,8);
\draw [add] (9.5,6) -- (10.25,5);
\draw [add] (9.5,5) -- (10.25,6);

\draw [add] (9.5,4) -- (10.25,3);
\draw [add] (9.5,3) -- (10.25,4);
\draw [add] (9.5,2) -- (10.25,1);
\draw [add] (9.5,1) -- (10.25,2);

\draw [add] (9.5,4) -- (10.25,4);
\draw [sub] (9.5,3) -- (10.25,3);
\draw [add] (9.5,2) -- (10.25,2);
\draw [sub] (9.5,1) -- (10.25,1);

% \draw[->] (e1) -- +(0pt,-25pt);
% \draw[->] (e2) -- +(0pt,25pt);
\end{tikzpicture}
\end{figure}

In this work we use the Fast Walsh Transform (FWT) to compute the nonlinearity of a Boolean function 
\cite{Shanks69-1}. A visual depiction of this algorithm is shown in Figure \ref{fig:fwt}.
The FWT computes the Walsh spectrum of a Boolean function given its truth 
table representation. Thus, given the previous definition of nonlinearity based on the Walsh transform, 
we may compute the nonlinearity of a Boolean function by taking the FWT of its truth table and then
subtracting half of the maximum absolute value entry in the output vector from $2^{n-1}$. 
It is well known that the time complexity of the FWT is $\mathcal{O}(n \ln n)$.

Python code for the implementation of the FWT is given in Listing \ref{list:fwt} as it is 
implemented in our analysis toolkit. In order to facilitate its use in the nonlinearity calculation
the zero entry of the vector is effectively zeroed out because it is simply the number of 
non-zero entries in the truth table, and each entry is doubled in size. 

\begin{lstlisting}[
language=Python, 
basicstyle=\small\sffamily,
numbers=left,
frame=tb,
columns=fullflexible,
showstringspaces=false,
caption=Python function to compute the Fast Walsh Tansform of a Boolean function.]
def fwt(f):
	wf = []
	for x in f:
		if x == 0:
			wf.append(1)
		else: # Assume a proper truth table of only 1 or 0 entries
			wf.append(-1)
	k = len(f) # k = 2^n
	n = int(math.log(k, 2))
	sw = 1
	bs = k - 1
	while True:
		li = 0
		bs = bs >> 1
		for b in range(bs, -1, -1):
			ri = li + sw
			for p in range(0, sw):
				a = wf[li]
				b = wf[ri]
				wf[li] = a + b
				wf[ri] = a - b
				li = li + 1
				ri = ri + 1
			li = ri
		sw = (sw << 1) & (k - 1)
		if (sw == 0):
			break
	return wf
\end{lstlisting} \label{lst:fwt}

The definition of nonlinearity for one-dimensional Boolean functions easily extends
to the nonlinearity of $(n,m)$-Boolean functions, denoted as $\mathcal{N}_l(F)$, which
is the minimum nonlinearity over all linear combinations of the $m$ coordinate functions
of the S-box. We formalize this definition in the following \cite{Carlet10-1}: 
\begin{align*}
\mathcal{N}_l(F) = \min_{c \in \mathbb{F}_2^m}\{c \cdot F\} = \min_{c \in \mathbb{F}_2^m}\{c_0f_0 \oplus c_1f_1 \oplus \dotsb \oplus c_{m-1}f_{m-1}\} 
\end{align*}
Cryptographically strong S-boxes have high measures of nonlinearity, meaning that
it is increasingly difficult to approximate the S-box using a linear affine function.
Subsequently, high measures of nonlinearity help hinder linear cryptanalysis attacks. 

The Python code to compute the nonlinearity for an $(n,n)$ S-box using the FWT 
is shown in Listing \ref{lst:nonlinearity}.

\begin{lstlisting}[
language=Python, 
basicstyle=\small\sffamily,
numbers=left,
frame=tb,
columns=fullflexible,
showstringspaces=false,
caption=Python function to compute the nonlinearity of an S-box $S$ defined as a map from input to output elements.]
def bf_nonlinearity(f, n):
	fw = fwt(f)
	for i in range(len(fw)):
		fw[i] = abs(fw[i])
	return ((2**(n-1)) - (max(fw) / 2)) # nonlinearity from the Walsh transform

def nonlinearity(S):
	order = len(S)
	n = int(math.log(order, 2))
	nl = 1 << order # over the top
	for mask in range(1, order): # For every linear combination of coordinate functions
		f = []
		for x in range(0, order): # Compute the inner product of the masked coordinate functions
			s = 0
			for i in range(0, n):
				if ((mask & (1 << i)) > 0) and ((S[x] & (1 << i)) > 0):
					s = s ^ 1;
			f.append(s)
		bfnl = bf_nonlinearity(f, n)
		if (bfnl < nl):
			nl = bfnl 
	return nl
\end{lstlisting} \label{lst:nonlinearity}

\subsection{Resiliency}
Resiliency is a combination of balancedness and correlation immunity. 
Balancedness is a simple property of Boolean functions;
a Boolean function is balanced if its (Hamming) weight is $2^{n - 1}$. 
A Boolean function $f$ on $n$ variables is said to have a correlation immunity 
of order $t$, $1 \leq t \leq n$, if the output is statistically independent for any fixed subset of at most $t$ 
variables. In other words, the output distribution probability is unchanged
when at most $t$ input variables are kept constant. A Boolean function is said
to be $t$-resilient if it is $t$-correlation immune and balanced. Similar to 
the nonlinearity metric for $(n,m)$ Boolean functions, an $(n,m)$ Boolean
function $F$ is said to be $t$ correlation immune if and only if all $2^m - 1$ Boolean
functions $v \cdot F, v \in \mathbb{F}_2^{m*}$ are $t$-th order correlation immune, and similarly, 
$F$ is $t$-resilient if and only if the all functions $2^m - 1$ Boolean
functions $v \cdot F, v \in \mathbb{F}_2^{m*}$ are $t$-resilient \cite{Carlet04-1}. 
Resiliency is an important property of cryptosystems with the advent of 
correlation attacks on stream ciphers \cite{Canteaut05-1}. Higher orders of resiliency,
and as a result, correlation immunity, are ideal for S-boxes.

\begin{lstlisting}[
language=Python, 
basicstyle=\small\sffamily,
numbers=left,
frame=tb,
columns=fullflexible,
showstringspaces=false,
caption=Python function to compute the resiliency of an S-box $S$ (i.e. the maximum $t$ such that $S$ is $t$-resilient).]

def resiliency(S):
	order = len(S)
	n = int(math.log(order, 2))
	for t in range(n, -1, -1):
		if isResilient(S, order, n, t) == False:
			return t - 1
def isResilient(S, order, n, t):
	for mask in range(1, order): # omit the 0 function
		f = []
		for x in range(0, order):
			s = 0
			for i in range(0, n):
				if ((mask & (1 << i)) > 0) and ((S[x] & (1 << i)) > 0):
					s = s ^ 1
			f.append(s)
		bf = BooleanFunction(f)
		bfr = bf.resiliency_order()
		if (bfr < t):
			return False
	return True
\end{lstlisting} \label{lst:resiliency}

\subsection{Algebraic Immunity}
This metric is used to determine a Boolean functions resilience to attacks
based on annihilators, which are used to deduce a multivariate equation
in the output of the function that have a low enough degree to solve efficiently.
Formally, an annihilator of a Boolean function $f$ is another a Boolean function $g$ such that $f \oplus g = 0$. 
Using low-degree annihilators it is sometimes possible to reduce the degree
of a Boolean function to a small enough value such that the system of 
equations relating the Boolean function and state bits of a cryptosystem
can be solved in a reasonable amount of time. 

With the development of the XSL attack on block ciphers by Curtois et al. \cite{Curtois02-1}, 
the notion of algebraic immunity has been extended to include its resistance to such attacks.
Curtois et al. presented the measurement $\Gamma(r, s, t) = (t/s)^{\lceil t/r \rceil}$ 
and $\Gamma'(r,s,t) = ((t - r)/s)^{\lceil (t - r)/s \rceil}$ to denote
the resistance against these attacks, where $r$ is the number equations that represent the 
S-box, $s$ is the size (in bits) of the S-box, and $t$ is the number of terms - the sparsity of terms - 
that appear in the $r$ equations. The difference between $\Gamma$ and $\Gamma'$ depends on the 
type of XSL attack; $\Gamma$ corresponds to the XSL attack that exploits knowledge of the 
key schedule of a block cipher, whereas $\Gamma'$ does not rely on this information. If 
biaffine equations are used in the XSL attack, then $t = s(s + 2) + 1$, and if fully quadratic
equations are used in the XSL attack, then $t = s(2s + 1) + 1$ \cite{Curtois05-1}. If we know
the dimension of the S-box $s$, then all that's left is to determine $r$, the 
number of linearly independent biaffine or fully quadratic equations. Curtois proved exact values for 
$r$ for a variety of cryptographically significant power mappings in \cite{Curtois05-1}. Yassir 
\cite{Nawaz09-1} generalized these results into an algorithm to compute the number of 
linearly biaffine and fully quadratic for arbitrary power mappings, which are 
transcribed in Algorithms \ref{biaffineNumber} and \ref{quadraticNumber}, respectively. 
We use these algorithms to compute $\Gamma(r,s,t)$ and $\Gamma'(r,s,t)$ for each candidate
S-box in the following chapter.

%\todo[inline]{Curtouis complexity estimate attack}
%\todo[inline]{Take a look at XL thesis: https://ritdml.rit.edu/bitstream/handle/1850/5072/TKaptanogluThesis01-2007.pdf?sequence=1}

%While high nonlinearity is an ideal property of S-boxes, there does exist

\begin{algorithm}[t!] %[htb]
\caption{Number of Linearly Independent Bi-Affine Equations \cite{Nawaz09-1}} \label{alg:biaffineNumber}
\begin{algorithmic}[1]
	\Require{$a$, $n > 1$}
	\State $cst_l \gets []$
	\State $cst_s \gets []$
	\For{$k = 0 \to n - 1$}
		\State $cs \gets COSET(2^k + a, 2^n - 1)$
		\State $cst_l \gets Append(cst_l, Min(cs))$
		\State $cst_s \gets Append(cst_s, Len(cs))$
	\EndFor
	\State Sort $cst_l$ in ascending order and rearrange $cst_s$ accordingly (i.e. if two elements in $cst_l$ are swapped then the
	corresponding elements in $cst_s$ should be swapped as well).
	\State $eqns \gets 0$
	\For{$k = 0 \to n - 1$}
		\If {WEIGHT$(cst_l[k]) = 1$}
			\State $eqns \gets eqns + n$
		\Else
			\If {$cst_s[k] < n$}
				\State $eqns \gets eqns + (n - cst_s[k])$
			\EndIf
			\If {$k \not= n - 1$ and  $cst_l[k] = cst_l[k+1]$}
				\State $eqns \gets eqns + cst_s[k]$
			\EndIf
		\EndIf	
	\EndFor
	\State \Return $eqns$
\end{algorithmic}
\end{algorithm}

\begin{algorithm}[t!] %[htb]
\caption{Number of Linearly Independent Quadratic Equations \cite{Nawaz09-1}} \label{alg:quadraticNumber}
\begin{algorithmic}[1]
	\Require{$a$, $m$, $n = 2m > 1$}
	\State $cst_l \gets []$
	\State $cst_s \gets []$
	\State $cstm_l \gets 0$, $cstm_s \gets 0$
	\For{$k = 0 \to n - 1$}
		\State $cs \gets COSET(2^k + a, 2^n - 1)$
		\State $cst_l \gets Append(cst_l, Min(cs))$
		\State $cst_s \gets Append(cst_s, Len(cs))$
	\EndFor
	\For{$k = 1 \to m - 1$}
		\State $cs \gets COSET((2^k + 1) \times a, 2^n - 1)$
		\State $cst_l \gets Append(cst_l, Min(cs))$
		\State $cst_s \gets Append(cst_s, Len(cs))$
	\EndFor
	\State $cs \gets COSET((2^m + 1) \times a, 2^n - 1)$
	\State $cstm_l \gets Min(cs), cstm_s \gets Len(cs)$
	\State Sort $cst_l$ in ascending order and rearrange $cst_s$ accordingly (i.e. if two elements in $cst_l$ are swapped then the
	corresponding elements in $cst_s$ should be swapped as well).
	\State $eqns \gets 0$
	\For{$k = 0 \to n + n - 1$}
		\If {$0 < $WEIGHT$(cst_l[k]) \leq 2$}
			\State $eqns \gets eqns + n$
		\Else
			\If {$cst_s[k] < n$}
				\State $eqns \gets eqns + (n - cst_s[k])$
			\EndIf
			\If {$k \not= n - 1$ and  $cst_l[k] = cst_l[k+1]$}
				\State $eqns \gets eqns + cst_s[k]$
			\EndIf
		\EndIf
	\EndFor
	\If {$0 < $WEIGHT$(cstm_l) \leq 2$}
		\State $eqns \gets eqns + m$
	\Else
		\If {$cstm_s < m$}
			\State $eqns \gets eqns + (m - cstm_s)$
		\EndIf
		\For {$k = 0 \to n + m - 1$}
			\If {$cstm_l = cst_l[k]$}
				\State $eqns \gets eqns + cstm_s$
				\State Break.
			\EndIf
		\EndFor
	\EndIf	
	\State \Return $eqns$
\end{algorithmic}
\end{algorithm}

Listing \ref{lst:cyclotomicCoset} shows the Python code that computes the cyclotomic coset for 
a given input $s$ and $n$. 

\label{lst:cyclotomicCoset}
\begin{lstlisting}[
language=Python, 
basicstyle=\small\sffamily,
numbers=left,
frame=tb,
columns=fullflexible,
showstringspaces=false,
caption=Python function to compute the cyclotomic coset $s$ modulo $n$.]
def coset(s, n):
	ns = 0
	for i in range(1, n):
		if ((s * (2 ** i)) % n == s):
			ns = i
			break
	cset = []
	for i in range(ns):
		cset.append((s * (2**i)) % n)
	return cset
\end{lstlisting}

\subsection{Branch Number}
While not directly related to a particular attack on the S-box, the \emph{branch number} ($\mathcal{B}_n$) corresponds
to the amount of diffusion provided by the particular mapping $f : \mathbb{F}_{2^n} \to \mathbb{F}_{2^n}$ \cite{daemen01-AES}. Mathematically, it is 
defined as:
\begin{align*}
\mathcal{B}_n = \min_{a \not= 0}\{\text{WEIGHT}(a) + \text{WEIGHT}(f(a)) \}
\end{align*}
Nonzero elements are referred to as \emph{active} elements because they determine which S-box elements will be used in the subsequent round of the cryptographic primitive.
As such, if the branch number is high, then the diffusion of input (plaintext) bits will be high among the output (ciphertext) bits a single round,
which is an important criteria for the S-box. Clearly, computing the branch number can be done trivially in $\mathcal{O}(2^n)$ time. 

It is also important to note that AUTHORS \cite{finding optimal bitslices implementations of 4x4 bit sboxes} define $\mathcal{B}_n$ in a 
different manner. In particular, they consider the branch number across all rounds of the cryptographic primitive, not just one. In doing so,
they change the definition as follows:
\begin{align*}
\mathcal{B}_n = \min_{a, b \not= a}\{\text{WEIGHT}(a + b) + \text{WEIGHT}(f(a) + f(b)) \}
\end{align*}
Given the earlier definition of the difference distribution table, it should be clear that the branch number depends on its contents. 
As a direct result, the branch number can be influenced by the affine transformation that is part of the S-box. Therefore, 
we reserve the calculation of this value until the final S-box has been constructed with the select power mapping
and affine transformation (see the following chapter for more details).

% \cite{finding optimal bitslices implementations of 4x4 bit sboxes}:
% \begin{align*}
% \mathcal{B}_n = \min_{a, b \not= a}\{\text{WEIGHT}(a + b) + \text{WEIGHT}(f(a) + f(b)) \}
% \end{align*}
% Intuitively, this means that small branch numbers imply that there exists two elements $a, b \in \mathbb{F}_{2^n}$
% such that the input 

\subsection{Algebraic Complexity} \label{sec:strength_alg_complexity}
Nonlinear S-boxes are traditionally based off of power mappings of the form $f(x) = x^d$ for some
exponent $d$. In the case of the AES, which uses the inverse power mapping $f(x) = x^{-1}$ we have 
that $d = 254$ by Fermat's Little Theorem. The S-box is then augmented with the linear transformation
shown below:
\begin{align*}
l(x) =  
\begin{pmatrix}
1 & 0 & 0 & 0 & 1 & 1 & 1 & 1 \\
1 & 1 & 0 & 0 & 0 & 1 & 1 & 1 \\
1 & 1 & 1 & 0 & 0 & 0 & 1 & 1 \\
1 & 1 & 1 & 1 & 0 & 0 & 0 & 1 \\
1 & 1 & 1 & 1 & 1 & 0 & 0 & 0 \\
0 & 1 & 1 & 1 & 1 & 1 & 0 & 0 \\
0 & 0 & 1 & 1 & 1 & 1 & 1 & 0 \\
0 & 0 & 0 & 1 & 1 & 1 & 1 & 1 \\
\end{pmatrix}
\begin{pmatrix}
x_0 \\
x_1 \\
x_2 \\
x_3 \\
x_4 \\ 
x_5 \\
x_6 \\
x_7 \\
\end{pmatrix}
+
\begin{pmatrix}
1 \\
1 \\
0 \\
0 \\
0 \\ 
1 \\
1 \\
0 \\
\end{pmatrix}
\end{align*}
Together, we have $S(x) = g \circ l \circ f $, where $g(x) = x \oplus 63$ and $f(x)$ 
is the inverse power mapping. Since $l(x)$ is a $GF(2)$-linear 
mapping over $GF(2^8)$, we may represent it as a linearized polynomial on $GF(2^8)$. 
In the case of AES, the linearized polynomial is equal to
\begin{align*}
f(a) = \sum_{i = 0}^{7}\lambda_i a^{2^{i}},
\end{align*}
where
\begin{align*}
(\lambda_0, \lambda_1, \lambda_2, \lambda_3, \lambda_4, \lambda_5, \lambda_6, \lambda_7) = (05, 09, F9, 25, F4, 01, B5, 8F),
\end{align*}
in hexadecimal notation and as elements in $GF(2^8)$. Together with the final $GF(2)$-linear addition with $x^6 + x^5 + x + 1 = 0x63$,
the linearized polynomial may be written as
\begin{align*}
f(a) = 05x^{2^{0}} + 09x^{2^{1}} + F9x^{2^{2}} + 25x^{2^{3}} + F4x^{2^{4}} + 01x^{2^{5}} + B5x^{2^{6}} + 8Fx^{2^{7}} + 63.
\end{align*}
Daemen and Rijmen state that the selection of the linear transformation $l(x)$ was chosen because it
provided a ``complex algebraic expression if combined with the inverse mapping'' \cite{Daemen02-1}, and the 
element $63 = x^6 + x^5 + x + 1$ was chosen in such a way that the S-box 
``has no fixed points and no opposite fixed points.'' That is, 
\begin{align*}
S(a) \oplus a \not= 00, \forall a \\
S(a) \oplus a \not= FF, \forall a.
\end{align*}
We define the algebraic complexity as the number of terms in this linearized polynomial. So, for the AES, the
algebraic complexity is equal to $9$. Some researchers fear that this is too low and may render variations of
interpolation attacks successful. As such, there has been ample research done to increase the algebraic complexity 
to much higher values. We discuss these results, in addition to the method for finding our proposed 
construction, in Chapter \ref{chp:sboxConstruction}.

% \todo[inline]{A design of Boolean functions resistant to (fast) algebraic cryptanalysis with efficient implementation}
